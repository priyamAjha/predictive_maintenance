{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\02213R744\\anaconda3\\envs\\patch_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import yaml\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('./tsfm_public')\n",
    "# Third Party\n",
    "from transformers import (\n",
    "    EarlyStoppingCallback,\n",
    "    PatchTSMixerConfig,\n",
    "    PatchTSMixerForPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tsfm_public.toolkit.dataset import ForecastDFDataset\n",
    "from tsfm_public.toolkit.time_series_preprocessor import TimeSeriesPreprocessor\n",
    "from tsfm_public.toolkit.util import select_by_index\n",
    "from read_data import loadData\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, testDatasets, expectedRulDatasets = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = ['setting_1', 'setting_2', 'setting_3'] \n",
    "data_clean = [data.drop(columns = drop_col) for data in data_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame()\n",
    "for i in range(4):\n",
    "    df_all =pd.concat([df_all, data_clean[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for engine in list(set(df_all['engine'])):\n",
    "    max_cycle = df_all[df_all['engine'] == engine]['cycle'].max() \n",
    "    condition = (df_all['engine'] == engine) & (df_all['cycle'] > max_cycle - 25)\n",
    "    df_all.loc[condition, 'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    152974\n",
       "1.0      7385\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engine_1 = df_all.drop(columns=['index'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_engine_1 = pd.DataFrame()\n",
    "# for i in range(len(data_clean)):\n",
    "#     df = data_clean[i][data_clean[i]['engine'] == 1].copy()  # Make a copy of the DataFrame\n",
    "#     max_cycle = df['cycle'].max()\n",
    "#     for j in range(df.shape[0]):\n",
    "#         if df.loc[j, 'cycle'] > max_cycle - 25:\n",
    "#             df.loc[j, 'label'] = 1\n",
    "#         else:\n",
    "#             df.loc[j, 'label'] = 0\n",
    "#     df_engine_1 = pd.concat([df_engine_1, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df_engine_1.drop(columns=['engine']).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr_columns = correlation_matrix[abs(correlation_matrix['label'] )> 0.03].index.tolist()\n",
    "# high_corr_colm = correlation_matrix[abs(correlation_matrix['label'] )> 0.03].T.columns\n",
    "\n",
    "df_sample = df_engine_1[high_corr_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cycle', 'Fan_inlet_temperature_R', 'Fan_inlet_Pressure_psia',\n",
       "       'bypass_duct_pressure_psia', 'HPC_outlet_pressure_psia',\n",
       "       'Ratio_of_fuel_flow_to_Ps30_pps_psia', 'Corrected_core_speed_rpm',\n",
       "       'High_pressure_turbines_Cool_air_flow',\n",
       "       'Low_pressure_turbines_Cool_air_flow', 'index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.drop(columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160359, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation_matrix = df_engine_1.drop(columns=['engine']).corr()\n",
    "# high_corr_colm = correlation_matrix[abs(correlation_matrix['label'] )> 0.03].T.columns\n",
    "# df_engine_1_sample_1 = df_engine_1[high_corr_colm]\n",
    "# df_engine_1_sample = df_engine_1_sample_1.drop(columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./config.yaml\", \"r\") as file:\n",
    "    configs = yaml.safe_load(file)\n",
    "\n",
    "num_workers = configs['num_workers'] # Reduce this if you have low number of CPU cores\n",
    "batch_size = configs['batch_size']  # Reduce if not enough GPU memory available\n",
    "context_length = configs['context_length'] \n",
    "forecast_horizon = configs['forecast_horizon']  # 8 hours \n",
    "patch_length = configs['patch_length'] \n",
    "# target_col = configs['target_columns']\n",
    "\n",
    "timestamp_column = \"cycle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.loc[:, 'index'] = df_sample.index\n",
    "data = df_sample.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cycle</th>\n",
       "      <th>Fan_inlet_temperature_R</th>\n",
       "      <th>Fan_inlet_Pressure_psia</th>\n",
       "      <th>bypass_duct_pressure_psia</th>\n",
       "      <th>HPC_outlet_pressure_psia</th>\n",
       "      <th>Ratio_of_fuel_flow_to_Ps30_pps_psia</th>\n",
       "      <th>Corrected_core_speed_rpm</th>\n",
       "      <th>High_pressure_turbines_Cool_air_flow</th>\n",
       "      <th>Low_pressure_turbines_Cool_air_flow</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>518.67</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.36</td>\n",
       "      <td>521.66</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>518.67</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.75</td>\n",
       "      <td>522.28</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>518.67</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.26</td>\n",
       "      <td>522.42</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cycle  Fan_inlet_temperature_R  Fan_inlet_Pressure_psia  \\\n",
       "0      1                   518.67                    14.62   \n",
       "1      2                   518.67                    14.62   \n",
       "2      3                   518.67                    14.62   \n",
       "\n",
       "   bypass_duct_pressure_psia  HPC_outlet_pressure_psia  \\\n",
       "0                      21.61                    554.36   \n",
       "1                      21.61                    553.75   \n",
       "2                      21.61                    554.26   \n",
       "\n",
       "   Ratio_of_fuel_flow_to_Ps30_pps_psia  Corrected_core_speed_rpm  \\\n",
       "0                               521.66                   8138.62   \n",
       "1                               522.28                   8131.49   \n",
       "2                               522.42                   8133.23   \n",
       "\n",
       "   High_pressure_turbines_Cool_air_flow  Low_pressure_turbines_Cool_air_flow  \\\n",
       "0                                 39.06                              23.4190   \n",
       "1                                 39.00                              23.4236   \n",
       "2                                 38.95                              23.3442   \n",
       "\n",
       "   index  \n",
       "0      0  \n",
       "1      1  \n",
       "2      2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_column = 'index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_columns = []\n",
    "forecast_columns = [col for col in data.columns if col not in timestamp_column]\n",
    "train_start_index = None  # None indicates beginning of dataset\n",
    "train_end_index = int(len(data)*configs['train_data_split']) \n",
    "# we shift the start of the validation/test period back by context length so that the first validation/test timestamp is immediately following the training data\n",
    "valid_start_index = int(len(data)*configs['train_data_split']) - context_length \n",
    "valid_end_index = int(len(data)*configs['train_data_split']) + int(len(data)*configs['valid_data_split']) \n",
    "test_start_index = int(len(data)*configs['train_data_split']) + int(len(data)*configs['valid_data_split']) - context_length \n",
    "test_end_index = len(data) \n",
    "\n",
    "train_data = select_by_index(\n",
    "    data,\n",
    "    id_columns=id_columns,\n",
    "    start_index=train_start_index,\n",
    "    end_index=train_end_index,\n",
    ")\n",
    "valid_data = select_by_index(\n",
    "    data,\n",
    "    id_columns=id_columns,\n",
    "    start_index=valid_start_index,\n",
    "    end_index=valid_end_index,\n",
    ")\n",
    "test_data = select_by_index(\n",
    "    data,\n",
    "    id_columns=id_columns,\n",
    "    start_index=test_start_index,\n",
    "    end_index=test_end_index,\n",
    ")\n",
    "tsp = TimeSeriesPreprocessor(\n",
    "    timestamp_column=timestamp_column,\n",
    "    id_columns=id_columns,\n",
    "    input_columns=forecast_columns,\n",
    "    output_columns=forecast_columns,\n",
    "    scaling=True,\n",
    ")\n",
    "\n",
    "tsp.train(train_data)\n",
    "\n",
    "train_dataset = ForecastDFDataset(\n",
    "    tsp.preprocess(train_data),\n",
    "    id_columns=id_columns,\n",
    "    input_columns=forecast_columns,\n",
    "    output_columns=forecast_columns,\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_horizon,\n",
    ")\n",
    "valid_dataset = ForecastDFDataset(\n",
    "    tsp.preprocess(valid_data),\n",
    "    id_columns=id_columns,\n",
    "    input_columns=forecast_columns,\n",
    "    output_columns=forecast_columns,\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_horizon,\n",
    ")\n",
    "test_dataset = ForecastDFDataset(\n",
    "    tsp.preprocess(test_data),\n",
    "    id_columns=id_columns,\n",
    "    input_columns=forecast_columns,\n",
    "    output_columns=forecast_columns,\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_horizon,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../model/patch_model/timeseriesprocessor.pkl\", \"wb\") as file:\n",
    "    pickle.dump(tsp, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PatchTSMixerConfig(\n",
    "        context_length=context_length,\n",
    "        prediction_length=forecast_horizon,\n",
    "        patch_length=patch_length,\n",
    "        num_input_channels=len(forecast_columns),\n",
    "        patch_stride=patch_length,\n",
    "        d_model=48,\n",
    "        num_layers=3,\n",
    "        expansion_factor=3,\n",
    "        dropout=0.5,\n",
    "        head_dropout=0.7,\n",
    "        mode=\"common_channel\", # change it `mix_channel` if we need to explicitly model channel correlations\n",
    "        scaling=\"std\",\n",
    "    )\n",
    "model = PatchTSMixerForPrediction(config=config)\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=\"./output/\",\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=configs['learning_rate'],\n",
    "    num_train_epochs=configs['epochs'],\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    dataloader_num_workers=num_workers,\n",
    "    report_to=\"tensorboard\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    logging_dir=\"./logs/\",  # Make sure to specify a logging directory\n",
    "    load_best_model_at_end=True,  # Load the best model when training ends\n",
    "    metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "    greater_is_better=False,  # For loss\n",
    "    label_names=[\"future_values\"],\n",
    ")\n",
    "# Create a new early stopping callback with faster convergence properties\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=5,  # Number of epochs with no improvement after which to stop\n",
    "    early_stopping_threshold=0.001,  # Minimum improvement required to consider as improvement\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\02213R744\\anaconda3\\envs\\patch_env\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Doing training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 60119/601190 [15:53<2:04:59, 72.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4861, 'learning_rate': 9e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 10%|█         | 60119/601190 [16:57<2:04:59, 72.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7522053122520447, 'eval_runtime': 64.6456, 'eval_samples_per_second': 247.936, 'eval_steps_per_second': 123.968, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 120238/601190 [32:27<1:58:27, 67.67it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4748, 'learning_rate': 8e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \n",
      " 20%|██        | 120238/601190 [33:29<1:58:27, 67.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7497198581695557, 'eval_runtime': 62.1479, 'eval_samples_per_second': 257.901, 'eval_steps_per_second': 128.95, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 180357/601190 [48:43<1:38:07, 71.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4734, 'learning_rate': 7e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \n",
      " 30%|███       | 180357/601190 [49:46<1:38:07, 71.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7491263747215271, 'eval_runtime': 63.0877, 'eval_samples_per_second': 254.059, 'eval_steps_per_second': 127.029, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 240476/601190 [1:04:50<1:27:10, 68.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4725, 'learning_rate': 6e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \n",
      " 40%|████      | 240476/601190 [1:05:52<1:27:10, 68.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7478170394897461, 'eval_runtime': 61.8744, 'eval_samples_per_second': 259.041, 'eval_steps_per_second': 129.52, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 300595/601190 [1:21:32<1:13:38, 68.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4718, 'learning_rate': 5e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \n",
      " 50%|█████     | 300595/601190 [1:22:33<1:13:38, 68.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7470899820327759, 'eval_runtime': 61.1498, 'eval_samples_per_second': 262.11, 'eval_steps_per_second': 131.055, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 360714/601190 [1:38:29<59:47, 67.04it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4711, 'learning_rate': 4e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \n",
      " 60%|██████    | 360714/601190 [1:39:33<59:47, 67.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7460920214653015, 'eval_runtime': 63.7144, 'eval_samples_per_second': 251.56, 'eval_steps_per_second': 125.78, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 420833/601190 [1:54:58<41:06, 73.12it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4707, 'learning_rate': 3e-05, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \n",
      " 70%|███████   | 420833/601190 [1:56:01<41:06, 73.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7457196712493896, 'eval_runtime': 62.9444, 'eval_samples_per_second': 254.637, 'eval_steps_per_second': 127.319, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 480952/601190 [2:11:33<27:35, 72.62it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4702, 'learning_rate': 2e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \n",
      " 80%|████████  | 480952/601190 [2:12:38<27:35, 72.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7452646493911743, 'eval_runtime': 64.3791, 'eval_samples_per_second': 248.963, 'eval_steps_per_second': 124.481, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 541071/601190 [2:27:32<13:54, 72.03it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4701, 'learning_rate': 1e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \n",
      " 90%|█████████ | 541071/601190 [2:28:34<16:30, 60.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7450457811355591, 'eval_runtime': 61.4648, 'eval_samples_per_second': 260.767, 'eval_steps_per_second': 130.384, 'epoch': 9.0}\n",
      "{'train_runtime': 8914.2347, 'train_samples_per_second': 134.883, 'train_steps_per_second': 67.442, 'train_loss': 0.47339749904009826, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12024/12024 [00:53<00:00, 226.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the foundation model at ../model/patch_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    callbacks=[early_stopping_callback],\n",
    ")\n",
    "print(\"\\n\\nDoing training\")\n",
    "trainer.train()\n",
    "trainer.evaluate(test_dataset)\n",
    "save_dir = configs['patch_foundation_model_path']\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "trainer.save_model(save_dir)\n",
    "print(f'Saved the foundation model at {configs[\"patch_foundation_model_path\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
